{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of different sampling methods to determine the optimal sampling strategy for the final OJO sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from dap_prinz_green_jobs.getters.ojo_getters import (\n",
    "    get_large_ojo_job_title_sample,\n",
    "    get_large_ojo_location_sample\n",
    ")\n",
    "\n",
    "from dap_prinz_green_jobs.getters.data_getters import load_s3_data\n",
    "from dap_prinz_green_jobs import BUCKET_NAME, config, PROJECT_DIR\n",
    "\n",
    "import altair as alt\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating /Users/india.kerlenesta/Projects/dap_green_jobs/dap_prinz_green_jobs/outputs/figures/sampling_analysis/231122 directory\n"
     ]
    }
   ],
   "source": [
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "random_seed = 42\n",
    "sample_size = 1000000\n",
    "\n",
    "#save graphs\n",
    "today = datetime.today().strftime('%y%m%d')\n",
    "graph_dir = str(PROJECT_DIR / f\"outputs/figures/sampling_analysis/{today}/\")\n",
    "\n",
    "if not os.path.exists(graph_dir):\n",
    "    print(f\"Creating {graph_dir} directory\")\n",
    "    os.makedirs(graph_dir)\n",
    "else:\n",
    "    print(f\"{graph_dir} directory already exists\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Load data\n",
    "- load current soc4 itl2 code large sample\n",
    "- unique soc4 code to job title json file\n",
    "- overall job locations data\n",
    "- deduplicated ids data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-22 10:23:55,486 - botocore.credentials - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2023-11-22 10:23:57,755 - botocore.credentials - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "#load SOC codes to job titles mapper\n",
    "soc_job_titles = load_s3_data(BUCKET_NAME, \"outputs/data/ojo_application/deduplicated_sample/jobtitles2soc4_production_true.json\")\n",
    "\n",
    "#load current sample information\n",
    "current_ojo_sample_titles = get_large_ojo_job_title_sample()\n",
    "current_ojo_sample_locations = get_large_ojo_location_sample()\n",
    "\n",
    "#load full locations and titles data \n",
    "locations_data = pd.read_parquet(config[\"ojo_s3_file_locations\"])\n",
    "locations_data = locations_data.drop_duplicates()\n",
    "\n",
    "all_titles = pd.read_parquet(config[\"ojo_s3_file_adverts_ojd_daps_extract\"])\n",
    "all_titles = all_titles.drop_duplicates(\n",
    "        subset=all_titles.columns.difference([\"created\"])\n",
    "    )\n",
    "\n",
    "#load deduplicated ids \n",
    "deduplicated_ids = pd.read_csv(\n",
    "        \"s3://prinz-green-jobs/outputs/data/ojo_application/deduplicated_sample/deduplicated_job_ids.csv\"\n",
    "    )\n",
    "deduplicated_ids_list = deduplicated_ids.id.to_list()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. sampling analysis\n",
    "\n",
    "look into:\n",
    "- **deduplication:** differences in deduplication between deduplicated ids and all_titles/locations\n",
    "- **sampling:** location differences in sampling between random sample and current sample data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 3618729 unique, deduplicated ids\n",
      "there are 7883041 unique ids from the full ojo sample job titles dataset\n",
      "45.91% of job ads are duplicates\n"
     ]
    }
   ],
   "source": [
    "# deduplication \n",
    "print(f\"there are {len(deduplicated_ids_list)} unique, deduplicated ids\")\n",
    "print(f\"there are {len(all_titles)} unique ids from the full ojo sample job titles dataset\")\n",
    "print(f\"{round((len(deduplicated_ids_list) / len(all_titles))*100, 2)}% of job ads are duplicates\")\n",
    "\n",
    "# are we deduplicating incorrectly? looks like we're loosing a lot of job ids. We might need to re-run the deduplication script\n",
    "# as we've collected more data since the projects start?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### randomly sample dataset + add soc4 codes to datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look into sampling - first lets merge the current title and locations samples and add soc4 codes\n",
    "\n",
    "sample_titles_locations = pd.merge(current_ojo_sample_titles, current_ojo_sample_locations, on='id')\n",
    "sample_titles_locations['soc4_code'] = sample_titles_locations['job_title_raw'].map(soc_job_titles)\n",
    "\n",
    "#now, let's take a random sample of 1,000,000 job titles from the full dataset and add soc4 codes\n",
    "full_titles_locations = pd.merge(all_titles, locations_data, on='id')\n",
    "full_titles_locations_sample = full_titles_locations.sample(n=sample_size, random_state=random_seed)\n",
    "full_titles_locations_sample['soc4_code'] = full_titles_locations_sample['job_title_raw'].map(soc_job_titles)\n",
    "\n",
    "#deduplicate the full dataset\n",
    "deduped_full_titles_locations = full_titles_locations.query('id in @deduplicated_ids_list')\n",
    "deduped_full_titles_locations_sample = deduped_full_titles_locations.sample(n=sample_size, random_state=random_seed)\n",
    "deduped_full_titles_locations_sample['soc4_code'] = deduped_full_titles_locations_sample['job_title_raw'].map(soc_job_titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 37 itl 2 codes in the oversampled dataset\n",
      "there are 37 itl 2 codes in the full dataset\n",
      "there are 37 itl 2 codes in the randomly dataset\n",
      "there are 37 itl 2 codes in the deduped randomly dataset\n",
      "\n",
      "there are 158 itl 3 codes in the oversampled dataset\n",
      "there are 159 itl 3 codes in the full dataset\n",
      "there are 159 itl 3 codes in the randomly dataset\n",
      "there are 159 itl 3 codes in the deduped randomly dataset\n"
     ]
    }
   ],
   "source": [
    "print(f\"there are {sample_titles_locations.itl_2_code.nunique()} itl 2 codes in the oversampled dataset\")\n",
    "print(f\"there are {full_titles_locations.itl_2_code.nunique()} itl 2 codes in the full dataset\")\n",
    "print(f\"there are {full_titles_locations_sample.itl_2_code.nunique()} itl 2 codes in the randomly dataset\")\n",
    "print(f\"there are {deduped_full_titles_locations_sample.itl_2_code.nunique()} itl 2 codes in the deduped randomly dataset\")\n",
    "\n",
    "print('')\n",
    "print(f\"there are {sample_titles_locations.itl_3_code.nunique()} itl 3 codes in the oversampled dataset\")\n",
    "print(f\"there are {full_titles_locations.itl_3_code.nunique()} itl 3 codes in the full dataset\")\n",
    "print(f\"there are {full_titles_locations_sample.itl_3_code.nunique()} itl 3 codes in the randomly dataset\")\n",
    "print(f\"there are {deduped_full_titles_locations_sample.itl_3_code.nunique()} itl 3 codes in the deduped randomly dataset\")\n",
    "\n",
    "\n",
    "#looks like theres pretty much all itl 2/3 codes are represented in the over/full/and randomly sampled datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampled sample analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0% of itl 2 codes have less than 100 job ads\n",
      "\n",
      "56.99999999999999% of itl 3 codes have less than 50 job ads\n",
      "71.0% of itl 3 codes have less than 100 job ads\n"
     ]
    }
   ],
   "source": [
    "itl2_counts = sample_titles_locations.groupby('itl_2_name').size().reset_index().rename(columns={0:'count'})\n",
    "itl2_counts['above_100'] = itl2_counts['count'] > 100\n",
    "\n",
    "itl3_counts = sample_titles_locations.groupby('itl_3_name').size().reset_index().rename(columns={0:'count'})\n",
    "itl3_counts['above_50'] = itl3_counts['count'] > 50\n",
    "itl3_counts['above_100'] = itl3_counts['count'] > 100\n",
    "\n",
    "print(f\"{round(len(itl2_counts.query('above_100 == False')) / len(itl2_counts), 2)*100}% of itl 2 codes have less than 100 job ads\")\n",
    "print('')\n",
    "print(f\"{round(len(itl3_counts.query('above_50 == False')) / len(itl2_counts), 2)*100}% of itl 3 codes have less than 50 job ads\")\n",
    "print(f\"{round(len(itl3_counts.query('above_100 == False')) / len(itl2_counts), 2)*100}% of itl 3 codes have less than 100 job ads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top itl codes in oversampled dataset\n",
    "itl_counts = sample_titles_locations.groupby('itl_2_name').size().sort_values(ascending=False).head(10).reset_index().rename(columns={0:'count'})\n",
    "itl_2_graph = alt.Chart(itl_counts, title=f\"top locations at itl 2 level\").mark_bar(opacity=0.2, color='red').encode(\n",
    "    x=alt.X('count', title='Number of job ads'),\n",
    "    #add label limit to be 50000\n",
    "    y=alt.Y(f'itl_2_name', title='', sort='-x', axis=alt.Axis(labelLimit=50000)))\n",
    "\n",
    "itl_counts = sample_titles_locations.groupby('itl_3_name').size().sort_values(ascending=False).head(10).reset_index().rename(columns={0:'count'})\n",
    "itl_3_graph = alt.Chart(itl_counts, title=f\"top locations at itl 3 level\").mark_bar(opacity=0.2, color='blue').encode(\n",
    "    x=alt.X('count', title='Number of job ads'),\n",
    "    #add label limit to be 50000\n",
    "    y=alt.Y(f'itl_3_name', title='', sort='-x', axis=alt.Axis(labelLimit=50000)))\n",
    "\n",
    "itl_counts_graphs = itl_2_graph | itl_3_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "soc4_itl2_counts = sample_titles_locations.groupby(['soc4_code', 'itl_2_code']).size().reset_index().rename(columns={0:'count'}).sort_values(by='count', ascending=True)\n",
    "soc4_itl2_counts['soc4_itl2'] = soc4_itl2_counts['soc4_code'] + ' - ' + soc4_itl2_counts['itl_2_code']\n",
    "\n",
    "soc4_itl2_counts['above_1'] = soc4_itl2_counts['count'] > 1\n",
    "soc4_itl2_counts['above_5'] = soc4_itl2_counts['count'] > 5\n",
    "soc4_itl2_counts['above_10'] = soc4_itl2_counts['count'] > 10\n",
    "soc4_itl2_counts['above_50'] = soc4_itl2_counts['count'] > 50\n",
    "\n",
    "above_1df = soc4_itl2_counts.above_1.value_counts().reset_index().rename(columns={'index':'above_1', 'above_1':'count'})\n",
    "more_than1_graph = alt.Chart(above_1df).mark_bar().encode(\n",
    "    y=alt.Y('above_1', title=''),\n",
    "    x=alt.X('count', title='Number of job ads'),\n",
    "    color=alt.Color('above_1', title='above 1', scale=alt.Scale(scheme='dark2'), legend=None)\n",
    ").properties(\n",
    "    title={\n",
    "      \"text\": [\"more than 1 job ad\"], \n",
    "      \"subtitle\": [f\"{(round(above_1df.query('above_1 == True')['count']/above_1df['count'].sum(), 2)*100).values[0]}% have more than 1 job ad\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "above_5df = soc4_itl2_counts.above_5.value_counts().reset_index().rename(columns={'index':'above_5', 'above_5':'count'})\n",
    "more_than5_graph = alt.Chart(above_5df).mark_bar().encode(\n",
    "    y=alt.Y('above_5', title=''),\n",
    "    x=alt.X('count', title='Number of job ads'),\n",
    "    color=alt.Color('above_5', title='above 5', scale=alt.Scale(scheme='dark2'), legend=None)\n",
    ").properties(\n",
    "    title={\n",
    "      \"text\": [\"more than 5 job ads\"], \n",
    "      \"subtitle\": [f\"{(round(above_5df.query('above_5 == True')['count']/above_5df['count'].sum(), 2)*100).values[0]}% have more than 5 job ads\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "above_10df = soc4_itl2_counts.above_10.value_counts().reset_index().rename(columns={'index':'above_10', 'above_10':'count'})\n",
    "more_than10_graph = alt.Chart(above_10df).mark_bar().encode(\n",
    "    y=alt.Y('above_10', title=''),\n",
    "    x=alt.X('count', title='Number of job ads'),\n",
    "    color=alt.Color('above_10', title='above 10', scale=alt.Scale(scheme='dark2'), legend=None)\n",
    ").properties(\n",
    "    title={\n",
    "      \"text\": [\"more than 10 job ads\"], \n",
    "      \"subtitle\": [f\"{(round(above_10df.query('above_10 == True')['count']/above_10df['count'].sum(), 2)*100).values[0]}% have more than 10 job ads\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "above_50df = soc4_itl2_counts.above_50.value_counts().reset_index().rename(columns={'index':'above_50', 'above_50':'count'})\n",
    "more_than50_graph = alt.Chart(above_50df).mark_bar().encode(\n",
    "    y=alt.Y('above_50', title=''),\n",
    "    x=alt.X('count', title='Number of job ads'),\n",
    "    color=alt.Color('above_50', title='above 10', scale=alt.Scale(scheme='dark2'), legend=None)\n",
    ").properties(\n",
    "    title={\n",
    "      \"text\": [\"more than 50 job ads\"], \n",
    "      \"subtitle\": [f\"{(round(above_50df.query('above_50 == True')['count']/above_50df['count'].sum(), 2)*100).values[0]}% have more than 10 job ads\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "oversample_charts = (itl_counts_graphs & (more_than1_graph | more_than5_graph) & (more_than10_graph | more_than50_graph)).properties(\n",
    "    title={\"text\": \"Sampling analysis for oversampled dataset of 1000000 deduplicated job ids\"}\n",
    ")\n",
    "\n",
    "oversample_charts.save(f'{graph_dir}/oversampled_analysis.html')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly sampled analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% of itl 2 codes have less than 100 job ads\n",
      "\n",
      "2.0% of itl 3 codes have less than 50 job ads\n",
      "7.000000000000001% of itl 3 codes have less than 100 job ads\n"
     ]
    }
   ],
   "source": [
    "itl2_counts = full_titles_locations_sample.groupby('itl_2_name').size().reset_index().rename(columns={0:'count'})\n",
    "itl2_counts['above_100'] = itl2_counts['count'] > 100\n",
    "\n",
    "itl3_counts = full_titles_locations_sample.groupby('itl_3_name').size().reset_index().rename(columns={0:'count'})\n",
    "itl3_counts['above_50'] = itl3_counts['count'] > 50\n",
    "itl3_counts['above_100'] = itl3_counts['count'] > 100\n",
    "\n",
    "print(f\"{round(len(itl2_counts.query('above_100 == False')) / len(itl2_counts), 2)*100}% of itl 2 codes have less than 100 job ads\")\n",
    "print('')\n",
    "print(f\"{round(len(itl3_counts.query('above_50 == False')) / len(itl2_counts), 2)*100}% of itl 3 codes have less than 50 job ads\")\n",
    "print(f\"{round(len(itl3_counts.query('above_100 == False')) / len(itl2_counts), 2)*100}% of itl 3 codes have less than 100 job ads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top itl codes in oversampled dataset\n",
    "itl_counts = full_titles_locations_sample.groupby(f'itl_2_name').size().sort_values(ascending=False).head(10).reset_index().rename(columns={0:'count'})\n",
    "itl_2_graph = alt.Chart(itl_counts, title=f\"top locations at itl 2 level\").mark_bar(opacity=0.2, color='green').encode(\n",
    "    x=alt.X('count', title='Number of job ads'),\n",
    "    #add label limit to be 50000\n",
    "    y=alt.Y(f'itl_2_name', title='', sort='-x', axis=alt.Axis(labelLimit=50000)))\n",
    "\n",
    "itl_counts = full_titles_locations_sample.groupby(f'itl_3_name').size().sort_values(ascending=False).head(10).reset_index().rename(columns={0:'count'})\n",
    "itl_3_graph = alt.Chart(itl_counts, title=f\"top locations at itl 3 level\").mark_bar(opacity=0.2, color='purple').encode(\n",
    "    x=alt.X('count', title='Number of job ads'),\n",
    "    #add label limit to be 50000\n",
    "    y=alt.Y(f'itl_3_name', title='', sort='-x', axis=alt.Axis(labelLimit=50000)))\n",
    "\n",
    "itl_counts_graphs = itl_2_graph | itl_3_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "soc4_itl2_counts = full_titles_locations_sample.groupby(['soc4_code', 'itl_2_code']).size().reset_index().rename(columns={0:'count'}).sort_values(by='count', ascending=True)\n",
    "soc4_itl2_counts['soc4_itl2'] = soc4_itl2_counts['soc4_code'] + ' - ' + soc4_itl2_counts['itl_2_code']\n",
    "\n",
    "soc4_itl2_counts['above_1'] = soc4_itl2_counts['count'] > 1\n",
    "soc4_itl2_counts['above_5'] = soc4_itl2_counts['count'] > 5\n",
    "soc4_itl2_counts['above_10'] = soc4_itl2_counts['count'] > 10\n",
    "soc4_itl2_counts['above_50'] = soc4_itl2_counts['count'] > 50\n",
    "\n",
    "above_1df = soc4_itl2_counts.above_1.value_counts().reset_index().rename(columns={'index':'above_1', 'above_1':'count'})\n",
    "more_than1_graph = alt.Chart(above_1df).mark_bar().encode(\n",
    "    y=alt.Y('above_1', title=''),\n",
    "    x=alt.X('count', title='Number of job ads'),\n",
    "    color=alt.Color('above_1', title='above 1', scale=alt.Scale(scheme='dark2'), legend=None)\n",
    ").properties(\n",
    "    title={\n",
    "      \"text\": [\"more than 1 job ad\"], \n",
    "      \"subtitle\": [f\"{(round(above_1df.query('above_1 == True')['count']/above_1df['count'].sum(), 2)*100).values[0]}% have more than 1 job ad\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "above_5df = soc4_itl2_counts.above_5.value_counts().reset_index().rename(columns={'index':'above_5', 'above_5':'count'})\n",
    "more_than5_graph = alt.Chart(above_5df).mark_bar().encode(\n",
    "    y=alt.Y('above_5', title=''),\n",
    "    x=alt.X('count', title='Number of job ads'),\n",
    "    color=alt.Color('above_5', title='above 5', scale=alt.Scale(scheme='dark2'), legend=None)\n",
    ").properties(\n",
    "    title={\n",
    "      \"text\": [\"more than 5 job ads\"], \n",
    "      \"subtitle\": [f\"{(round(above_5df.query('above_5 == True')['count']/above_5df['count'].sum(), 2)*100).values[0]}% have more than 5 job ads\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "above_10df = soc4_itl2_counts.above_10.value_counts().reset_index().rename(columns={'index':'above_10', 'above_10':'count'})\n",
    "more_than10_graph = alt.Chart(above_10df).mark_bar().encode(\n",
    "    y=alt.Y('above_10', title=''),\n",
    "    x=alt.X('count', title='Number of job ads'),\n",
    "    color=alt.Color('above_10', title='above 10', scale=alt.Scale(scheme='dark2'), legend=None)\n",
    ").properties(\n",
    "    title={\n",
    "      \"text\": [\"more than 10 job ads\"], \n",
    "      \"subtitle\": [f\"{(round(above_10df.query('above_10 == True')['count']/above_10df['count'].sum(), 2)*100).values[0]}% have more than 10 job ads\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "above_50df = soc4_itl2_counts.above_50.value_counts().reset_index().rename(columns={'index':'above_50', 'above_50':'count'})\n",
    "more_than50_graph = alt.Chart(above_50df).mark_bar().encode(\n",
    "    y=alt.Y('above_50', title=''),\n",
    "    x=alt.X('count', title='Number of job ads'),\n",
    "    color=alt.Color('above_50', title='above 10', scale=alt.Scale(scheme='dark2'), legend=None)\n",
    ").properties(\n",
    "    title={\n",
    "      \"text\": [\"more than 50 job ads\"], \n",
    "      \"subtitle\": [f\"{(round(above_50df.query('above_50 == True')['count']/above_50df['count'].sum(), 2)*100).values[0]}% have more than 10 job ads\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "random_sample_charts = (itl_counts_graphs & (more_than1_graph | more_than5_graph) & (more_than10_graph | more_than50_graph)).properties(\n",
    "    title={\"text\": \"Sampling analysis for randomly sampled dataset of 1000000 job ids\"}\n",
    ")\n",
    "\n",
    "random_sample_charts.save(f'{graph_dir}/random_sample_analysis.html')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dedupled randomly sampled analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% of itl 2 codes have less than 100 job ads\n",
      "\n",
      "2.0% of itl 3 codes have less than 50 job ads\n",
      "12.0% of itl 3 codes have less than 100 job ads\n"
     ]
    }
   ],
   "source": [
    "itl2_counts = deduped_full_titles_locations_sample.groupby('itl_2_name').size().reset_index().rename(columns={0:'count'})\n",
    "itl2_counts['above_100'] = itl2_counts['count'] > 100\n",
    "\n",
    "itl3_counts = deduped_full_titles_locations_sample.groupby('itl_3_name').size().reset_index().rename(columns={0:'count'})\n",
    "itl3_counts['above_50'] = itl3_counts['count'] > 50\n",
    "itl3_counts['above_100'] = itl3_counts['count'] > 100\n",
    "\n",
    "print(f\"{round(len(itl2_counts.query('above_100 == False')) / len(itl2_counts), 2)*100}% of itl 2 codes have less than 100 job ads\")\n",
    "print('')\n",
    "print(f\"{round(len(itl3_counts.query('above_50 == False')) / len(itl2_counts), 2)*100}% of itl 3 codes have less than 50 job ads\")\n",
    "print(f\"{round(len(itl3_counts.query('above_100 == False')) / len(itl2_counts), 2)*100}% of itl 3 codes have less than 100 job ads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top itl codes in oversampled dataset\n",
    "itl_counts = deduped_full_titles_locations_sample.groupby(f'itl_2_name').size().sort_values(ascending=False).head(10).reset_index().rename(columns={0:'count'})\n",
    "itl_2_graph = alt.Chart(itl_counts, title=f\"top locations at itl 2 level\").mark_bar(opacity=0.2, color='green').encode(\n",
    "    x=alt.X('count', title='Number of job ads'),\n",
    "    #add label limit to be 50000\n",
    "    y=alt.Y(f'itl_2_name', title='', sort='-x', axis=alt.Axis(labelLimit=50000)))\n",
    "\n",
    "itl_counts = deduped_full_titles_locations_sample.groupby(f'itl_3_name').size().sort_values(ascending=False).head(10).reset_index().rename(columns={0:'count'})\n",
    "itl_3_graph = alt.Chart(itl_counts, title=f\"top locations at itl 3 level\").mark_bar(opacity=0.2, color='purple').encode(\n",
    "    x=alt.X('count', title='Number of job ads'),\n",
    "    #add label limit to be 50000\n",
    "    y=alt.Y(f'itl_3_name', title='', sort='-x', axis=alt.Axis(labelLimit=50000)))\n",
    "\n",
    "itl_counts_graphs = itl_2_graph | itl_3_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "soc4_itl2_counts = deduped_full_titles_locations_sample.groupby(['soc4_code', 'itl_2_code']).size().reset_index().rename(columns={0:'count'}).sort_values(by='count', ascending=True)\n",
    "soc4_itl2_counts['soc4_itl2'] = soc4_itl2_counts['soc4_code'] + ' - ' + soc4_itl2_counts['itl_2_code']\n",
    "\n",
    "soc4_itl2_counts['above_1'] = soc4_itl2_counts['count'] > 1\n",
    "soc4_itl2_counts['above_5'] = soc4_itl2_counts['count'] > 5\n",
    "soc4_itl2_counts['above_10'] = soc4_itl2_counts['count'] > 10\n",
    "soc4_itl2_counts['above_50'] = soc4_itl2_counts['count'] > 50\n",
    "\n",
    "above_1df = soc4_itl2_counts.above_1.value_counts().reset_index().rename(columns={'index':'above_1', 'above_1':'count'})\n",
    "more_than1_graph = alt.Chart(above_1df).mark_bar().encode(\n",
    "    y=alt.Y('above_1', title=''),\n",
    "    x=alt.X('count', title='Number of job ads'),\n",
    "    color=alt.Color('above_1', title='above 1', scale=alt.Scale(scheme='dark2'), legend=None)\n",
    ").properties(\n",
    "    title={\n",
    "      \"text\": [\"more than 1 job ad\"], \n",
    "      \"subtitle\": [f\"{(round(above_1df.query('above_1 == True')['count']/above_1df['count'].sum(), 2)*100).values[0]}% have more than 1 job ad\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "above_5df = soc4_itl2_counts.above_5.value_counts().reset_index().rename(columns={'index':'above_5', 'above_5':'count'})\n",
    "more_than5_graph = alt.Chart(above_5df).mark_bar().encode(\n",
    "    y=alt.Y('above_5', title=''),\n",
    "    x=alt.X('count', title='Number of job ads'),\n",
    "    color=alt.Color('above_5', title='above 5', scale=alt.Scale(scheme='dark2'), legend=None)\n",
    ").properties(\n",
    "    title={\n",
    "      \"text\": [\"more than 5 job ads\"], \n",
    "      \"subtitle\": [f\"{(round(above_5df.query('above_5 == True')['count']/above_5df['count'].sum(), 2)*100).values[0]}% have more than 5 job ads\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "above_10df = soc4_itl2_counts.above_10.value_counts().reset_index().rename(columns={'index':'above_10', 'above_10':'count'})\n",
    "more_than10_graph = alt.Chart(above_10df).mark_bar().encode(\n",
    "    y=alt.Y('above_10', title=''),\n",
    "    x=alt.X('count', title='Number of job ads'),\n",
    "    color=alt.Color('above_10', title='above 10', scale=alt.Scale(scheme='dark2'), legend=None)\n",
    ").properties(\n",
    "    title={\n",
    "      \"text\": [\"more than 10 job ads\"], \n",
    "      \"subtitle\": [f\"{(round(above_10df.query('above_10 == True')['count']/above_10df['count'].sum(), 2)*100).values[0]}% have more than 10 job ads\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "above_50df = soc4_itl2_counts.above_50.value_counts().reset_index().rename(columns={'index':'above_50', 'above_50':'count'})\n",
    "more_than50_graph = alt.Chart(above_50df).mark_bar().encode(\n",
    "    y=alt.Y('above_50', title=''),\n",
    "    x=alt.X('count', title='Number of job ads'),\n",
    "    color=alt.Color('above_50', title='above 10', scale=alt.Scale(scheme='dark2'), legend=None)\n",
    ").properties(\n",
    "    title={\n",
    "      \"text\": [\"more than 50 job ads\"], \n",
    "      \"subtitle\": [f\"{(round(above_50df.query('above_50 == True')['count']/above_50df['count'].sum(), 2)*100).values[0]}% have more than 10 job ads\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "deduped_random_sample_charts = (itl_counts_graphs & (more_than1_graph | more_than5_graph) & (more_than10_graph | more_than50_graph)).properties(\n",
    "    title={\"text\": \"Sampling analysis for randomly sampled dataset of 1000000 deduplicated job ids\"}\n",
    ")\n",
    "\n",
    "deduped_random_sample_charts.save(f'{graph_dir}/random_deduped_sample_analysis.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save all of them together! \n",
    "\n",
    "(deduped_random_sample_charts | random_sample_charts | oversample_charts).save(f'{graph_dir}/sampling_analysis.html')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takeaways:\n",
    "- the **weighted sample** is quite skewed at the itl3 level i.e. most regions have fewer than 100 job ads and half have fewer than 50 job ads.\n",
    "- the deduplication method does get rid of almost half of the job adverts: i wonder if its worth re-running the script as I know jack's been collecting job ads? I don't think that will change the results drastically but could be good to be updated\n",
    "- we would still need to oversample in a few regions if we move forward with a totally random sample "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dap_prinz_green_jobs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1165a7969a9687ff40a9a1cba7fbc27daccde7acf9ca503596a533568b05dd6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
