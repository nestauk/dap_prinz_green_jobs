"""
Custom prodigy recipe to generate both NER start and end tokens of company description
    and the predicted SIC code using an LLM.

To run the custom recipe:

prodigy oa_ner_classification comp_sic_annotated \
    dap_prinz_green_jobs/pipeline/green_measures/industries/prodigy/data/mixed_ojo_sample_5000.jsonl \
    -F dap_prinz_green_jobs/pipeline/green_measures/industries/prodigy/custom_openai_recipe.py
"""
import langchain
from langchain.llms import OpenAIChat
from langchain.output_parsers import StructuredOutputParser, ResponseSchema
from langchain.prompts import PromptTemplate
from pathlib import Path

from dotenv import load_dotenv
import copy
import os
import re
from typing import Iterator, List, Union

import prodigy
import spacy
from prodigy.components.loaders import JSONL
from prodigy.components.preprocess import add_tokens

load_dotenv()  # load the openAI key

if not os.getenv("OPENAI_API_KEY"):
    ValueError(
        "OPENAI_API_KEY not found in environment variables. Add key to .env file."
    )

model = OpenAIChat(model="gpt-3.5-turbo", temperature=0.0)

ner_schema = [
    ResponseSchema(
        name="sic_phrase",
        description="Predict the company description sentence in the input text. It must be an exact phrase from the input text.",
    ),
    ResponseSchema(
        name="sic_code",
        description="Based on the company description sentence, predict the 2007 Standardised Industrial Classification (SIC) code up to the 4 digit level. It must be a string.",
    ),
    ResponseSchema(
        name="sic_name",
        description="The description that corresponds to the predicted 2007 Standardised Industrial Classification (SIC) code. It must be a string.",
    ),
]


def _make_prompt(
    schema: List[ResponseSchema] = ner_schema,
) -> Union[PromptTemplate, StructuredOutputParser]:
    """Generate the prompt template and ouput parser for the recipe.

    Args:
        schema (List[ResponseSchema], optional): List of ResponseSchema objects. Defaults to prodigy_schema.

    Returns:
        Union[PromptTemplate, StructuredOutputParser]: PromptTemplate and StructuredOutputParser objects.
    """
    # parse the schema
    output_parser = StructuredOutputParser.from_response_schemas(schema)
    format_instructions = output_parser.get_format_instructions()

    # generate the prompt template
    prompt = PromptTemplate(
        template='Predict the company description phrase and the SIC name based on the predicted company description phrase in a job advert.\n{format_instructions}\n The job advert text is in the triple quotes below: \n"""{job_advert}"""\n',
        input_variables=["job_advert"],
        partial_variables={"format_instructions": format_instructions},
    )

    return prompt, output_parser


def make_tasks(
    nlp: spacy.language.Language,
    stream: Iterator[dict],
    schema: List[ResponseSchema] = ner_schema,
    model: langchain.llms.OpenAI = model,
) -> Iterator[dict]:
    """Add predicted entities generated by OpenAI to the stream.

    Args:
        nlp (spacy.language.Language): spaCy language model
        schema (List[ResponseSchema]): List of ResponseSchema objects
        model (langchain.llms.OpenAI): OpenAI language model

    Yields:
        Iterator[dict]: Iterator of dictionaries with text and spans keys
    """
    prompt, output_parser = _make_prompt(schema)
    texts = ((eg["text"], eg) for eg in stream)
    for doc, eg in nlp.pipe(texts, as_tuples=True):
        spans = []
        task = copy.deepcopy(eg)
        _input = prompt.format_prompt(job_advert=doc.text)
        output = model(_input.to_string())
        # light touch json cleaning if LLM returns a bad json
        if not output.endswith("```"):
            output = output[: output.rfind("\n")] + "```"
        try:
            output_parsed = output_parser.parse(output)
        # deal with bad parsing and just let the labeller identify the SIC phrase and code
        except langchain.schema.OutputParserException:
            output_parsed = None
        if output_parsed:
            match = re.search(re.escape(output_parsed["sic_phrase"]), doc.text)
            if match:
                start, end = match.start(), match.end()
                span = doc.char_span(start, end, alignment_mode="expand")
                token_start, token_end = span.start, span.end - 1

            spans.append(
                {
                    "start": start,
                    "end": end,
                    "token_start": token_start,
                    "token_end": token_end,
                    "label": "SIC_CODE",
                }
            )
        else:
            spans.append(
                {
                    "start": 0,
                    "end": 0,
                    "token_start": 0,
                    "token_end": 0,
                    "label": "SIC_CODE",
                }
            )

        task["spans"] = spans

        options = [
            {"id": 1, "text": output_parsed["sic_phrase"]},
            {
                "id": 1,
                "text": f"{output_parsed['sic_code']} ({output_parsed['sic_name']})",
            },
            {"id": 3, "text": "wrong SIC code"},
        ]
        task["options"] = options

        yield task


@prodigy.recipe(
    "oa_ner_classification",
    dataset=("The dataset to use", "positional", None, str),
    source=("The source data as a .jsonl file", "positional", None, Path),
)
def custom_oa(dataset, source):
    # load blank spacy model
    nlp = spacy.blank("en")

    # Initialize the Prodigy stream
    stream = JSONL(source)

    # add tokens to the stream
    stream = add_tokens(nlp, stream)

    # add predicted entities and text to the stream
    stream = make_tasks(nlp, stream)

    return {
        "dataset": dataset,  # save annotations in this dataset
        "view_id": "blocks",  # use the blocks interface
        "stream": stream,
        "config": {
            "buttons": ["accept", "reject", "ignore"],
            "labels": ["SIC_CODE"],  # the label for the manual NER interface
            "blocks": [
                {"view_id": "ner_manual"},
                {"view_id": "choice", "text": None},
            ],
        },
    }
