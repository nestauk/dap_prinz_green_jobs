"""
Custom prodigy recipe to generate both NER start and end tokens of company description
    and the predicted SIC code using an LLM.

To run the custom recipe:

prodigy oa_ner_classification comp_desc_annotated \
    dap_prinz_green_jobs/pipeline/span_extraction/data/mixed_ojo_sample_10.jsonl \
    -F dap_prinz_green_jobs/pipeline/span_extraction/custom_openai_recipe.py
"""
import langchain
from langchain.llms import OpenAI
from langchain.output_parsers import StructuredOutputParser, ResponseSchema
from langchain.prompts import PromptTemplate
from pathlib import Path

from dotenv import load_dotenv
import copy
import os
import re
from typing import Iterator, List, Union

import prodigy
import spacy
from prodigy.components.loaders import JSONL
from prodigy.components.preprocess import add_tokens


load_dotenv()  # load the openAI key

if not os.getenv("OPENAI_API_KEY"):
    ValueError(
        "OPENAI_API_KEY not found in environment variables. Add key to .env file."
    )

model = OpenAI(temperature=0.0)

ner_schema = [
    ResponseSchema(
        name="sic_phrase",
        description="Predict the company description sentence in the input text. It must be an exact phrase from the input text. It must be a string.",
    ),
    ResponseSchema(
        name="sic_code",
        description="Based on the predicted company description sentence, predict the SIC code. Must be a Standardised Industry Code.",
    ),
    ResponseSchema(
        name="sic_name",
        description="The description of the predicted SIC code. Must be the description of the Standardised Industry Code.",
    ),
]


def _make_prompt(
    schema: List[ResponseSchema] = ner_schema,
) -> Union[PromptTemplate, StructuredOutputParser]:
    """Generate the prompt template and ouput parser for the recipe.

    Args:
        schema (List[ResponseSchema], optional): List of ResponseSchema objects. Defaults to prodigy_schema.

    Returns:
        Union[PromptTemplate, StructuredOutputParser]: PromptTemplate and StructuredOutputParser objects.
    """
    # parse the schema
    output_parser = StructuredOutputParser.from_response_schemas(schema)
    format_instructions = output_parser.get_format_instructions()

    # generate the prompt template
    prompt = PromptTemplate(
        template='Predict the SIC code and the phrase that generated the SIC code prediction in the job advert text.\n{format_instructions}\n The job advert text is in the triple quotes below: \n"""{job_advert}"""\n',
        input_variables=["job_advert"],
        partial_variables={"format_instructions": format_instructions},
    )

    return prompt, output_parser


def make_tasks(
    nlp: spacy.language.Language,
    stream: Iterator[dict],
    schema: List[ResponseSchema] = ner_schema,
    model: langchain.llms.OpenAI = model,
) -> Iterator[dict]:
    """Add predicted entities generated by OpenAI to the stream.

    Args:
        nlp (spacy.language.Language): spaCy language model
        schema (List[ResponseSchema]): List of ResponseSchema objects
        model (langchain.llms.OpenAI): OpenAI language model

    Yields:
        Iterator[dict]: Iterator of dictionaries with text and spans keys
    """
    prompt, output_parser = _make_prompt(schema)
    texts = ((eg["text"], eg) for eg in stream)
    for doc, eg in nlp.pipe(texts, as_tuples=True):
        spans = []
        task = copy.deepcopy(eg)
        _input = prompt.format_prompt(job_advert=doc.text)
        output = model(_input.to_string())
        # light touch json cleaning if LLM returns a bad json
        if not output.endswith("```"):
            output = output[: output.rfind("\n")] + "```"
        try:
            output_parsed = output_parser.parse(output)
        # deal with bad parsing and just let the labeller identify the SIC phrase and code
        except langchain.schema.OutputParserException:
            output_parsed = None
        if output_parsed:
            # use regex instead of an llm to find the phrase in the text
            pattern = r"\b{}\b".format(re.escape(output_parsed["sic_phrase"]))
            # you only want the first match
            matches = [
                (match.start(), match.end()) for match in re.finditer(pattern, doc.text)
            ]
            matches = matches[0] if matches else None
            if matches:
                start, end = matches[0], matches[1]
                charspan = doc.char_span(start, end)
                if charspan:
                    token_start, token_end = charspan.start, charspan.end - 1
            else:
                start, end, token_start, token_end = 0, 0, 0, 0

            spans.append(
                {
                    "start": start,
                    "end": end,
                    "token_start": token_start,
                    "token_end": token_end,
                    "label": "SIC_CODE",
                }
            )
        else:
            spans.append(
                {
                    "start": 0,
                    "end": 0,
                    "token_start": 0,
                    "token_end": 0,
                    "label": "SIC_CODE",
                }
            )

        task["spans"] = spans
        options = [
            {
                "id": 1,
                "text": f"{output_parsed['sic_code']} ({output_parsed['sic_name']})",
            },
            {"id": 2, "text": "wrong SIC code"},
        ]
        task["options"] = options

        yield task


@prodigy.recipe(
    "oa_ner_classification",
    dataset=("The dataset to use", "positional", None, str),
    source=("The source data as a .jsonl file", "positional", None, Path),
)
def custom_oa(dataset, source):
    # load blank spacy model
    nlp = spacy.blank("en")

    # Initialize the Prodigy stream
    stream = JSONL(source)

    # add tokens to the stream
    stream = add_tokens(nlp, stream)

    # add predicted entities and text to the stream
    stream = make_tasks(nlp, stream)

    return {
        "dataset": dataset,  # save annotations in this dataset
        "view_id": "blocks",  # use the blocks interface
        "stream": stream,
        "config": {
            "buttons": ["accept", "reject", "ignore"],
            "labels": ["SIC_CODE"],  # the label for the manual NER interface
            "blocks": [
                {"view_id": "ner_manual"},
                {"view_id": "choice", "text": None},
            ],
            "custom_theme": {
                "labels": {"SIC_CODE": "#2592da"},
            },
        },
    }
